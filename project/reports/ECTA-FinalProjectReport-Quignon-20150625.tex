\documentclass[conference]{IEEEtran}

\usepackage[T1]{fontenc} 

\usepackage[utf8]{inputenc}  

\usepackage[pdftex]{graphicx} 

\graphicspath{{img/}} 

\DeclareGraphicsExtensions{.pdf,.eps,.mps, .png}  

\usepackage[caption=false,font=footnotesize]{subfig} 

% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.

% *** CITATION PACKAGES ***
%
\usepackage{cite}
% \cite{} output to follow that of IEEE. Loading the cite package will

% *** GRAPHICS RELATED PACKAGES ***
%
%\ifCLASSINFOpdf
%  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
%  \graphicspath{{/img}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
%  \DeclareGraphicsExtensions{.png}
%\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
%  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
%  \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
%  \DeclareGraphicsExtensions{.eps}
%\fi

% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500

% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}

% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}

%\usepackage{mdwmath}
%\usepackage{mdwtab}

%\usepackage{eqparbox}

% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{F}

%\usepackage[caption=false]{caption}
%\usepackage[sfont=footnotesize]{subfig}
%\usepackage[caption=false,font=footnotesize]{subfig}

% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}

%\usepackage{stfloats}
%\begin{figure*}[!b]" is not normally possible in
% LaTeX2e It also provides a command:
%\fnbelowfloat

% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch.

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% \url{my_url_here}.


% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{}


\begin{document}

\title{Predicting energy consumption of a heat pump
by evolving decision trees.}

\author{\IEEEauthorblockN{Christophe Quignon}
\IEEEauthorblockA{Bonn-Rhein-Sieg University of Applied Sciences\\
Email: christophe.quignon@smail.inf.h-brs.de}
}

\maketitle


\begin{abstract}
In this project, I explored the capabilities of evolving decision trees to predict the energy consumption of a heat pump. Data from a real heat pump was recorded in a timespan of 242 days. From this data approximately 16.561 sample sets of input an output data where used to evolve a decision tree. The tree was evaluated on 557 samples (8 days) to validate the prediction accuracy.\\
The algorithm evolved a decision tree by mutation either the split value of a node or the predicted outcome. As crossover method, a node or leaf of one tree was replaced by a node or leaf of another tree.\\
Despite a wide range of parameters, it was not possible to gain a steady improvement of prediction accuracy. It could be shown that this was not due to a bad parameter choice but that it is most likely due to the unstable  fitness function. This may be overcome by several measures including a more performant implementation.
\end{abstract}
\IEEEpeerreviewmaketitle



\section{Problem}

Heat pumps are a sustainable way to transfer thermal energy from the ground into buildings to maintain a comfortable temperature. But to operate a heating pump is not a trivial task. Different building distribute the heat differently and weather with its chaotic nature has a major influence on the temperature flow. With an accurate prediction of the energy consumption, one can increase their efficiency and decrease the operating cost.\\
This project explored the possibilities to enhance on a regular trained random forest. The idea is to optimize the random choice of the decision value and the random prediction value to increase its predictive power.\\
For the optimization, an evolutionary strategy was chosen to modify the decision and prediction values. As a fitness estimate, a random subset of input and prediction values was drawn and the mean squared error (MSE) calculated and used as a fitness value to minimize. 

\subsection{Former work}
\label{sec:formerwork}
In a different project ("Learning and Adaptivity"), a random forest was trained on the same dataset. After several optimizations, an $R^{2}$ score of $0.89$ was achieved. The reason to use a random forest was that from the decision trees, general "human readable" rules could be extracted to control the heat pumps. As of now, the control of the heat pump happens with simple thresholds on values and resulting actions, which closely assembles the working of decision trees.


\subsection{Data} 
\label{sec:data}
The Recogizer GmbH provided a dataset of 4 sensor readings, three weather indicators and an accumulated daily energy consumption. In 242 days (between July 2014 to February 2015), over 1,300,000 data points where collected.

\paragraph{Weather data:}
The regional weather is included with a frequency of one measurement per hour. It is collected from the official recordings of the "Deutsche Wetterdienst" (German weather service) and contains:

\begin{itemize}
	\item Outside temperature in $^\circ C$
	\item Relative air humidity in percent
	\item Precipitation in $mm$ ($l/m^{2}$)
\end{itemize}


\paragraph{Sensor data:}
The heat pump itself is equipped with several sensor that once every minute measure the following metrics:
\begin{itemize}
	\item Volumetric flow rate in $m^3 / s$
	\item Power in $watts$
	\item Input temperature in $^\circ C$
	\item Output temperature $^\circ C$
\end{itemize}

\paragraph{Accumulated data:}
The total energy consumption of the system in watt hours is added up every day. Thus it is the least frequent feature.


\subsection{Evolving decision trees}
\label{sec:GARF}

To have a basic understanding of decision trees I will give a short overview of their working. For further insight several tutorials like \cite{quinlan1986induction} are available. Here it is sufficient to know how the prediction step of one branch is working. Given an $n$-dimensional input, a decision tree node splits the data into two subsets. The split is defined by one random dimension of the input set and one random value in this dimension. The two sets are then passed to the next level of the tree where they are again split along a possibly different dimension with possibly different random values. At the leafs of the tree finally stand prediction values.\\
A first random decision tree is not expected to produce a meaningful output, but small changes in good decision trees are likely to drive the fitness value towards the optimal fitness value. In summation, the problem is favouring small increments on existing good solutions over exploring the whole solution space. Thus an evolutionary strategy was chosen over a genetic algorithm.
The idea to then optimize the decision tree with a genetic algorithm was first formulated in \cite{bader2012garf} where it is called "Genetic Algorithm based Random Forests" (GARF).
%TODO option to write more


\section{Preprocessing}

As with every data, preprocessing was necessary to gain a good prediction. In this case, the raw values of the sensor where normalized between zero (minimal value) and one(maximum value).

The single dimensions where all subsampled to the same frequency to avoid implicit weighting by having more samples of one dimension then the other.

In former work (See section \ref{sec:formerwork}) it was experimentally shown that the precipitation did not contribute to the performance of any learning algorithm, because its values where to sparse. Thus it also was not included in this approach.
On the other hand, including additional information about the time in form of a an increasing value, namely the day of the year increased the prediction accuracy of all analysed algorithms and thus also was included in this approach. This allows for a comprehensive prediction comparison, because both algorithms start with the very same data inputs. It however is not clear how or whether at all a decision tree could exploit the day of the year. Since the power is linearly related to the energy consumption, it is also not used in the input set.

%\subsection{Correlation}
%two subsets of relations (internal and external)
%Feature merge not done (temperature delta)
%As part of the preprocessing, a further analysis of the data was done. One mayor insight was gained by the correlation of the single input dimensions. On the 

\subsection{Seasonal decomposition}
Heat pumps are strongly affected by the weather and thus have a seasonal behaviour. In every dimension, one can clearly identify the day in form of a low temperature night, a steep decline when the sun rises and a steady cooling once it set. Additionally this effect accumulates during the warm month and is less visible in the cold month. The seasonal decomposition by \cite{loess} made it possible to clearly identify this seasonal trends and extract it.\\
With the general seasonal information of one day the delay of the system could be found. The daily progress of every parameter was convoluted with the to predict energy. Thus the time delay of every parameter could be identified by the time delay of maximum overlap with the energy. For internal measurements like input and output temperature was naturally low (7 minutes) and could be logically reasoned as the time the heat transferring liquid travels through the system. The most influential parameter (outside temperature) was in forerun to the energy by three hours. This means that the structural features of the building hold back temperature change for as long as three hours. This maximal time shift defined the minimal time frame for every input. In this case, a larger input frame of 24 hours was chosen to maximize the information available.


\subsection{Sliding window approach}
It also was important to use the maximum of information along the dimensions. With general regression, from a set of input dimensions a different output dimension at the same time is learned. This would mean that the learning algorithm would learn how to calculate the current energy given all other measurements. But the energy consumption at the same moment is known and thus not necessary to learn. Instead the current energy should also be used as an input and the energy of the next day is the anticipated output of the function. In this case, the input vector is every dimension at the current time point and the to predict output is the energy consumed on the next day Thus the algorithm can use the current energy as a state which already is a good estimate for future consumption. This technique called "Sliding window approach" is explained and analysed in detail in \cite{vafaeipour2014application}.\\
This maximisation of input could be further improved by also including some reasonable knowledge about the future. Weather forecast with a lookahead of one single day is quite reliable and could be used to further improve the algorithm. This however would also mean that the recorded weather forecast would be needed for training. This at the moment is not the case.\\
The three possible configuration of input and output as described above are depicted in figure \ref{fig:timeshift}.

%TIMESHIFT
\begin{figure}[!t] 
\centering 
\includegraphics[width=0.45\textwidth]{LA-regpred.png} 
\caption{Input(green) and output (red) frames for prediction (left), sliding window (middle) and prediction enhanced (yellow) sliding window (right).} 
\label{fig:timeshift} 
\end{figure}

\subsection{Sampling}
For analytical simplicity and the algorithm to perform in reasonable time, the maximum sampling rate of one minute was not used. Instead the input frame was subsampled to 20 minutes. With 9 input dimensions this makes a total of 657 dimensions at the input.\\
On the output, the daily energy consumption naturally is only one value per day. However the sampling rate of 20 minutes at the input also defines the number of samples we have in total and per day. Thus every daily energy consumption is defined by 72 samples and the total of 242 days is sampled 17424 times. This allows to average all predictions to gain a more likely prediction. Those samples in the end where split into a training set and a test set which contained the last 10 days of recording.


\section{Algorithm}
As stated in section \ref{sec:GARF}, an evolutionary strategy was chosen over a genetic algorithm. In this section I discuss the basic workings and design choices of the evolutionary strategy used. Besides the discussion of the genome, the mutation and selection and the fitness value in the following paragraphs it is necessary to point out that the algorithm used elitism on the best individual and limited the maximum tree depth for mutation to 30. This allows for maximum tree depth of 60, if a complete tree of depth 30 is crossed over with a leaf of another tree that also has a tree depth of 30. This tree however can not crossover any more.
This puts a theoretical limit of $2^{30}$ leaf values and $2^{30} - 2^{29}$ splits, which in practice is not a limit in this problem.\\

\subsection{Genome}
The genome of the evolutionary algorithm is the decision tree itself.
On a node position, it contains a dimension along with the split value and its dimension. The split itself is defined as a $\leq$ relation which allows 0 values as splits. 
At the leafs is a prediction value between 0 and 1. The structure of the tree is defined as a data structure and can not be mutated but only changed by crossover. The limits between 1 and 0 only apply because of the normalization of the data in the preprocessing step.\\
This structure can be thought of as an explicit genetic program that is evolved. Explicit because it is not compiled but executed as functions on the decision tree. It also is not a genetic program, because it only contains the $\leq$ operation for the splits and only values as outputs. Without other mathematical functions that actually work on the inputs, this is only similar to genetic programming. However the implication of tree depth, balancedness, node and leaf mutation and possible crossover method as described in \cite{banzhaf1998genetic} also apply.

\subsection{Fitness}
As with every evolutionary algorithm, a fitness function has to be defined. For predictions, the mean squared error (MSE) between the predicted and the actual value is an obvious choice. \\
In this particular application, the MSE was calculated after every algorithm iteration, based on a random sub sample of $ n $input/output pairs. The inputs of all $n$ samples where propagated through the nodes of the decision tree, and the difference between the predictions and the actual energy consumption was assigned to the tree as a fitness that was to minimize. This random  subsampling results in an unstable fitness value which then possibly leads to an unstable order if individuals in the population. This may enhance diversity of the population but also puts a lower bound on the minimum that can be reached. This can never be lower then the variance of the MSEs of the random subsamples, because inside this variance, a good fit is by chance and will not survive multiple fitness evaluations.

\subsection{Mutation}
The mutation of the decision tree is likely to greatly influence the outcome. Thus the prediction value is only initially randomly chosen from the input space. Afterwards, the split values as well as the prediction values are mutated with a value drawn from a Gaussian distribution. The Mean for the distribution is the value before mutation. A Sigma defines the standard deviation from that value. Since all values are normalized between zero and one, the same Sigma is used for all mutation, be it leafs or nodes. For the same reason, values beyond zero or one are cut off. The sigma is fixed for the whole run and was not changed. Thus a mutation changes, dependent on the position it happens either the split value (nodes) or the prediction value (leafs) with a Gaussian distribution.

\subsection{Selection and recombination}
The selection is based on the fitness values of the individual decision trees in the population. The individual with the best fitness is carried over into the next iteration without modification (Elitism).\\
The recombination and the amount of individuals can be chosen freely from the complete set of $(\mu ,\lambda)$, and $(\mu + \lambda)$ evolutionary strategies as defined in \cite{rozenberg2011handbook}. In the current implementation, computational limits are put upon the choice by the number of the total population size. The population size and the number of random samples for the fitness function are the scaling factors for the memory usage.

\section{Analysis}
\subsection{Parameters}
From the algorithms design, several parameters arise that can influence the performance. The parameters tuned in total where:

\begin{itemize}
\item The number of iterations to run
\item The selection type $(\mu \{, +\} \lambda)$
\item The mutation variance (Sigma)
\item The mutation probability for the leafs
\item The mutation probability for the nodes
\item The initial tree depth
\item The number of samples for the fitness value
\end{itemize}

It was not possible to test all combinations of all parameters and thus I decided to optimize only a few likely good parameters in two sets.
Of those parameters, two groups with similar context where formed. 
The number of iterations, the selection type and the mutation variance all are parameters mostly independent from the problem, where the mutation probabilities, the initial tree depth  and the number of samples are directly linked to the solution quality. The parameters of the other set where kept static with an expected good value. Thus I had two runs which where used to evaluate the parameters:

\begin{enumerate}
\item 
\begin{itemize}
\item Iterations to run = \{100, 200, 400\}
\item Selection type = \{2+2,  4+16, 4+32, 4,16\}
\item Sigmas = \{0.4, 0.2, 0.1, 0.05, 0.005\}
\item Initial tree depth = 12
\item Leaf mutation probability = 0.1
\item Node mutation probability = 0.8
\item Fitness samples = 500
\end{itemize}

With a total of 60 runs.\\

\item
\begin{itemize}
\item Iterations to run = 200
\item Selection type = 4+16
\item Sigma = 0.2
\item Initial tree depth = \{6, 12\}
\item Leaf mutation probability = \{0.4, 0.2, 0.1, 0.01\}
\item Node mutation probability = \{0.8, 0.6, 0.4, 0.2\}
\item Fitness samples = \{100, 500, 1000\}
\end{itemize}
With a total of 69 runs.\\
\end{enumerate}
For every run, the progress of the minimal, maximal and mean fitness value was recorded and plotted. Additionally, at the end of the run, the best individual was presented an input training set of the last 10 days of the recordings. (See figure \ref{fig:winner} and figure \ref{fig:best}) That formerly unseen input sample then was fed to the fitness function to compute the mean squared error to the actual energy consumption. The prediction along with the actual values also where plotted. All parameters, the minimal fitness value and the MSE of the train set where recorded to evaluate the parameters.


\subsection{Algorithm behaviour}
From the recorded fitness progress, the fit from the training set and the recordings of the parameters, I could gain insight in the algorithm behaviour in general and with respect to the parameters.\\
In general, the algorithm quickly (often within the first 20 iterations) found a local optima. In some cases, one or two additional local minima where found. Those improvements usually where instant and not incrementally achieved. Besides the use of elitism, the minimal fitness was unstable because of the random sub sampling. The gap between the minimal and maximal fitness, which indicated diversity in the population usually is very small or not present at all. In a few cases, the population temporarily gained a diversity boost, indicated by a sudden split of minimal, mean and maximal fitness. This however was not reproducible with the same parameters and thus random. In addition, no positive or negative effect on the final fitness value could be measured. All in all, the optimization was not stable.\\
With respect to the parameters, the visual examination of the fitness progress led no clear picture. Neither did the prediction of the test set. Neither the absolute predicted values, not their position of change gave any indication of a successfully learned prediction. The values where mostly within the middle range where the measured energy consumption lied. The changes of values did not match the daily change of the energy value. Additionally, the different prediction values also varied a lot. In most of the more successful runs, there was only one prediction value which roughly corresponded to the mean. But there also where a lot of runs with more than 10 values that did neither relate to the trend of energy consumption nor the fixed time frame, where the energy consumption changed every day.

\subsection{Parameter correlation}
To validate the weak visual indications, the correlation of the parameters and the fitness value was calculated. As depicted in figure \ref{fig:param_correlation}, the correlation of the parameters with the fitness is almost zero. One exception is the selection type, because a $(\mu,\lambda)$ selection with a low population size (below 30) is not able to sustain a stable solution and thus randomly loses good solutions and often got thrown back to the initial random initialisation. Other than that, this means that this particular algorithm can not be optimized by the choice of parameters on this concrete problem. Thus the choice of parameters could not systematically be improved. More runs with less likely and computationally more expensive parameters also ended without success.

%PARAM CORRELATION
\begin{figure}[!t] 
\centering 
\includegraphics[width=0.45\textwidth]{paramruns_corellation.png} 
\caption{Parameter correlation.} 
\label{fig:param_correlation} 
\end{figure}


\subsection{Fitness and prediction}
\label{sec:fitness_prediction}
%TODO rename
The correlation matrix also indicates one more problem with the algorithm. As one can see in figure \ref{fig:param_correlation}, the correlation between the fitness value and the prediction accuracy also is quite low. This means, that for a significant portion of runs, the fitness value was no good indicator for the predicted energy consumption. Or to put it the other way around: a good predictor did not necessarily receive a good fitness.\\
This clearly is by no means acceptable for an optimization algorithm and thus was further examined. All runs where ordered by their fitness and then the parameters where plotted in the same order to see their correlation. As depicted in figure \ref{fig:mse_comparison}, the correlation is only significant at the extremes.

%MSE COMPARISON
\begin{figure}[!t] 
\centering 
\includegraphics[width=0.45\textwidth]{paramruns_mse.png} 
\caption{Comparison of the general MSE (fitness) and the prediction MSE.} 
\label{fig:mse_comparison} 
\end{figure}

\subsection{Result}
As described in section \ref{sec:fitness_prediction}, the optimization was neither stable nor the result of steady improvement. Thus it is not of relevance, which result was the best, because it can not reliably be reproduced. I however will use the example of the best fitness value (see figure \ref{fig:winner}) and the best prediction (see figure \ref{fig:best}) to point the weaknesses of the algorithm.\\
The fitness progress of the individual with the best fitness is not typical. We see a gradual decrease of the fitness between the 25th and 50th iteration. In most of the other runs this optimization happens in one step. What is typical here is the high fluctuation in the fitness value. Besides the use of elitism the fitness value for almost half the size of the first significant optimization step. This also makes clear that an optimization to be visible has to be greater than this fluctuation and a stable improvement inside this fluctuation is likely to be reverted later. It is also typical that the three recorded fitness values (maximum in red, mean in blue and minimum in blue) often are the same, which means that all individuals predicted the same. This however does not mean they are the same. The prediction of the best fitness is representative for a good portion of the results. The predicted value is at no time close to the actual energy value and the changes in value do not align with the change of the day every 72nd 20th minute (scale on the x axis). It also does not reflect the fitness value and thus can not be justified to be more than random with a little luck.\\
On the other hand, we have the individual which did the best estimate of the prediction. It also performed bad with its actual fitness value in comparison to the other runs, but it was nonetheless the best individual of its run. The prediction is also representative. A large portion of predictions just where one single line. Either because the decision tree only was one leaf or because the splits learned left out only one value for the whole range of input data. It closely assembles the actual energy consumption but is not a useful prediction because it does not consider the input.\\
The fitness progress again is interesting. It was one of only a few runs, where the population over several iterations split off into different but somewhat stable solutions. The population diverged quickly and stood that way even if a clear winner is visible. Only after some more iterations the population again collapses to similar individuals and stayed that way up until the end.


%WINNER
\begin{figure*}[!t]
\centerline{\subfloat[Fitness progress of the lowest final MSE 0.0277.]{\includegraphics[width=2.5in]{0p0277-2p2.png}%
\label{fig:winner_fitness}}
\hfil
\subfloat[Prediction of the last 10 days with a date frequency of 20 minutes with the lowest final MSE with a predictive MSE of 0.0568.]{\includegraphics[width=2.5in]{best-0p0277=0p05678-2+2.png}%
\label{fig:winner_prediction}}}
\caption{Analysis of the lowest final MSE of all runs.}
\label{fig:winner}
\end{figure*}


%BEST
\begin{figure*}[!t]
\centerline{\subfloat[Fitness progress of the lowest prediction MSE of 0.0019.]{\includegraphics[width=2.5in]{0p0537-2+2.png}%
\label{fig:best_fitness}}
\hfil
\subfloat[Prediction of the last 10 days with a date frequency of 20 minutes with the lowest prediction MSE and an final MSE of 0.05374.]{\includegraphics[width=2.5in]{best-0p05374=0p0019-2+2.png}%
\label{fig:best_prediction}}}
\caption{Analysis of the lowest prediction MSE of all runs.}
\label{fig:best}
\end{figure*}

\subsection{Comparison}
As stated at the beginning, the project was aimed to improve a random forest prediction. The final prediction of the random forest is shown in figure \ref{fig:random_forest}. It shows a clear relation between the predicted values and the actual measurements and is obviously systematically better than the decision tree. As argued before this difference is not due to the systematic inferiority of a decision tree to a random forest, but to a lack of prediction power in the evolved decision tree. Even if several decision trees where accumulated to a random forest, one could not expect a meaningful prediction.

%RANDOM FOREST PREDICTION
\begin{figure}[!t] 
\centering 
\includegraphics[width=0.45\textwidth]{LA-predict-energy--0p890.png} 
\caption{Prediction of the energy consumption (y - axis) of the last eight days of the dataset in steps of 10 minutes (x-axis) with a Random Forest.} 
\label{fig:random_forest} 
\end{figure}

\section{Conclusion}
AS discussed in detail, the presented implementation of the algorithm is not able to significantly improve a random decision tree to predict the energy consumption from a high dimensional input. This inability is independent from the parameters which where tested on a comprehensive set of values. Single runs produced a reasonably good prediction, but no indication for a better then random result could be found.
Instead, it was shown that the fitness value correlates only weakly with the prediction performance.\\
During the runs and the evaluation, several severe faults that also could happen in similar optimization problems where found:

\begin{itemize}
\item An random component in the fitness function will make it unstable
\item An unstable fitness function puts a limit on the optimal solution found
\end{itemize}

After eliminating those fault several other improvements could lead to a stable optimization:

\begin{itemize}
\item  A memory and computationally efficient implementation would allow for more samples and thus reduce the randomness of the fitness function.
\item Other crossover and mutation methods could lead to a more systematic improvement.
\item The decision tree could be changed towards a genetic program by including other splits or leaf nodes that calculate and not only insert values.
\item A more focused control over the tree depth and split dimensionality could lead to more insight. As suggested by \cite{gathercole1996adverse} and advances in random forests, the depth is a highly relevant parameter for a good performing genetic program as well as a random forest.
\item Performance could also be used to enforce more iterations or a greater population size and thus a greater chance to randomly find other, possibly better optima.  This however is unlikely by the observations so far.
\item Introduction of a non static Sigma could also enable the algorithm to find local optima. This however is unlikely by the observations so far.
\end{itemize}

With these improvements it would also be possible to advance further on the concrete problem by:

\begin{itemize}
\item Evolving a forest of genetically evolved decision trees
\item Including weather forecast into the inputs
\item Compare the performance in detail with other prediction algorithms.
\end{itemize}

To end on a positive note, it was demonstrated how careful statistical analysis of different runs with different parameters should lead the way to insights on the performance of the algorithm and the parameters. Visual scans of progress plots and prediction result can and often will be led by expectations and distorted by the confirmation bias.

\bibliographystyle{IEEEtran}
\bibliography{bib}

% \bibliography{IEEEabrv, bib.bib}

\end{document}


